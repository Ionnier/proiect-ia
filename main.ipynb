{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# !pip install pyphen nltk pandas sklearn\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphen\n",
    "import cupy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pronouncing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_validate\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from dale_chall import DALE_CHALL\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\"sentence\": \"string\", \"token\": \"string\", \"complexity\": \"float64\"}\n",
    "train = pd.read_excel(os.path.join(os.getcwd(), \"data\",\n",
    "                      \"train.xlsx\"), dtype=dtypes, keep_default_na=False)\n",
    "test = pd.read_excel(os.path.join(os.getcwd(), \"data\",\n",
    "                     \"test.xlsx\"), dtype=dtypes, keep_default_na=False)\n",
    "#print('train data: ', train.shape)\n",
    "#print('test data: ', test.shape)\n",
    "\n",
    "def accuracy(y_true: np.array, y_pred: np.array):\n",
    "    return np.sum((y_true == y_pred).astype(int)) / len(y_true) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"complex\"] == False].to_csv(\"simple.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_syllables(word):\n",
    "    return len(pyphen.Pyphen(lang=\"en\").inserted(word,\"-\").split(\"-\"))\n",
    "\n",
    "def is_dale_chall(word):\n",
    "        return (word.lower() in DALE_CHALL) or (WordNetLemmatizer().lemmatize(word, pos=\"n\") in DALE_CHALL)\n",
    "\n",
    "\n",
    "def length(word):\n",
    "    return len(word.replace(\" \", \"\"))\n",
    "\n",
    "\n",
    "def nr_vowels(word):\n",
    "    vowels = [\"a\", \"e\", \"o\", \"u\",\n",
    "     \"i\", \"y\"]\n",
    "    nr_vowels = 0\n",
    "    word = word.lower()\n",
    "    for vowel in vowels:\n",
    "        nr_vowels += word.count(vowel)\n",
    "    return nr_vowels\n",
    "\n",
    "def nr_consoane(word):\n",
    "    vowels = [\"b\",\"c\",\"d\",\"f\",\"g\",\"h\",\"j\",\"k\",\"l\",\"m\",\"n\",\"p\",\"q\",\"r\",\"s\",\"t\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "    nr_cons = 0\n",
    "    word = word.lower()\n",
    "    for vowel in vowels:\n",
    "        nr_cons += word.count(vowel)\n",
    "    return nr_cons\n",
    "\n",
    "\n",
    "def is_title(word):\n",
    "    if word == word.capitalize():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def abreviation(word):\n",
    "    if word == word.upper():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def repeating_characters(word):\n",
    "    chars = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    word = word.lower()\n",
    "    characters = 0\n",
    "    for char in chars:\n",
    "        count = word.count(char)\n",
    "        if count > 1:\n",
    "            characters += 1\n",
    "    return characters == 0\n",
    "\n",
    "\n",
    "text = [ x.strip().encode(\"ascii\", \"ignore\") for x in list(train['sentence'])]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(text)\n",
    "vectorizer.get_feature_names_out()\n",
    "df_tfid = pd.DataFrame(data = X.toarray(),columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "def get_tfid(word):\n",
    "    try:\n",
    "        li = list(df_tfid[word])\n",
    "        return sum(li)/len(li)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_word_structure_features(word):\n",
    "    features = []\n",
    "    features.append(nr_syllables(word))\n",
    "    features.append(is_dale_chall(word))\n",
    "    features.append(length(word))\n",
    "    features.append(nr_vowels(word))\n",
    "    features.append(is_title(word))\n",
    "    #features.append(abreviation(word))\n",
    "    #features.append(prononciation(word))\n",
    "    #features.append(get_tfid(word))\n",
    "    #features.append(repeating_characters(word))\n",
    "    features.append(nr_consoane(word))\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def get_wordnet_features(word):\n",
    "    features = []\n",
    "    features.append(len(wordnet.synsets(word)))\n",
    "    # try:\n",
    "    #     len(wordnet.synsets(word)[0].definition())\n",
    "    #     features.append(1)\n",
    "    # except:\n",
    "    #     features.append(0)\n",
    "    # try:\n",
    "    #     len(wordnet.synsets(word)[0].examples())\n",
    "    #     features.append(1)\n",
    "    # except:\n",
    "    #     features.append(0)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def get_position_in_sentence(sentence, word):\n",
    "    try:\n",
    "        cp_sentence = sentence.lower()\n",
    "        cp_word = word.lower()\n",
    "        words = re.findall(r'\\w+', cp_sentence)\n",
    "        position = words.index(cp_word)\n",
    "        return [int(position/len(words)) * 10]\n",
    "    except ValueError:\n",
    "        words = sentence.split(' ')\n",
    "        for x in range(len(words)):\n",
    "            if word in words[x]:\n",
    "                return [int(x/len(words)) * 10]\n",
    "\n",
    "\n",
    "def complex_sentence(sentence):\n",
    "    for x in sentence:\n",
    "        if(ord(x) > 127):\n",
    "            return [True]\n",
    "    return [False]\n",
    "\n",
    "\n",
    "def mean_complexity_sentence(sentence):\n",
    "    array = []\n",
    "    for x in word_tokenize(sentence):\n",
    "        array.append(get_word_structure_features(x))\n",
    "    return [np.array(array).mean()]\n",
    "\n",
    "\n",
    "def unique_words(sentence):\n",
    "    dictionar = {}\n",
    "    for x in word_tokenize(sentence):\n",
    "        try:\n",
    "            dictionar[x] += 1\n",
    "        except:\n",
    "            dictionar[x] = 1\n",
    "    return [len(dictionar)]\n",
    "\n",
    "\n",
    "def corpus_feature(corpus):\n",
    "    corp_dict = {}\n",
    "    corp_dict['bible'] = [0]\n",
    "    corp_dict['europarl'] = [1]\n",
    "    corp_dict['biomed'] = [2]\n",
    "    return corp_dict[corpus]\n",
    "    \n",
    "def prononciation(word):\n",
    "    try:\n",
    "        pronouncing.phones_for_word(word)[0].split()\n",
    "        return 0\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "row = train.iloc[:1]\n",
    "# print(corpus_feature(row['corpus'])[0])\n",
    "\n",
    "\n",
    "def featurize(row):\n",
    "    word = row['token']\n",
    "    all_features = []\n",
    "    all_features.extend(corpus_feature(row['corpus']))\n",
    "    all_features.extend(get_word_structure_features(word))\n",
    "    #all_features.extend(get_wordnet_features(word))\n",
    "    #all_features.extend(complex_sentence(row['sentence']))\n",
    "    #all_features.extend(mean_complexity_sentence(row['sentence']))\n",
    "    #all_features.extend(unique_words(row['sentence'])) #extremly unimportant\n",
    "    #all_features.extend(get_position_in_sentence(row['sentence'], word))\n",
    "    return np.array(all_features)\n",
    "\n",
    "\n",
    "def featurize_df(df):\n",
    "    nr_of_features = len(featurize(df.iloc[0]))\n",
    "    nr_of_examples = len(df)\n",
    "    features = np.zeros((nr_of_examples, nr_of_features))\n",
    "    for index, row in df.iterrows():\n",
    "        row_ftrs = featurize(row)\n",
    "        features[index, :] = row_ftrs\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays_of_indexes = []\n",
    "for x in train[\"corpus\"].unique():\n",
    "    arrays_of_indexes.append(train.loc[train['corpus'] == x].index)\n",
    "\n",
    "\n",
    "def generate_data(percentage=15):\n",
    "    chosen_idx = []\n",
    "    for array in arrays_of_indexes:\n",
    "        chosen_idx.extend(np.random.choice(\n",
    "            array, replace=False, size=int(percentage/100*len(array))))\n",
    "    new_test = train.iloc[chosen_idx]\n",
    "    new_train = train.drop(chosen_idx)\n",
    "    new_train.reset_index(drop=True, inplace=True)\n",
    "    new_test.reset_index(drop=True, inplace=True)\n",
    "    X_train = featurize_df(new_train)\n",
    "    y_train = new_train['complex'].values\n",
    "    X_test = featurize_df(new_test)\n",
    "    y_test = new_test['complex'].values\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predicitons(X_train, y_train, X_test, neighbours):\n",
    "    model = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "\n",
    "for nb in [1, 3, 5, 7]:\n",
    "    scor = []\n",
    "    for _ in range(20):\n",
    "        X_train, y_train, X_test, y_test = generate_data(5)\n",
    "        preds = knn_predicitons(X_train, y_train, X_test, nb)\n",
    "        scor.append(balanced_accuracy_score(y_test, preds))\n",
    "    print(nb, np.array(scor).mean())\n",
    "\n",
    "\"\"\" Submission 3\n",
    "knn 3 neighbours \n",
    "\n",
    "100 random train data of 15% of total\n",
    "\n",
    "features.append(nr_syllables(word))\n",
    "    features.append(is_dale_chall(word)) // without plural bonus\n",
    "    features.append(length(word))\n",
    "    features.append(nr_vowels(word))\n",
    "    features.append(is_title(word))\n",
    "    features.append(abreviation(word))\n",
    "    features.append(repeating_characters(word))\n",
    "\n",
    "default row features\n",
    "\n",
    "1 0.668427876407733\n",
    "2 0.6126221801373262\n",
    "3 0.6765161869511589\n",
    "4 0.6386154857166626\n",
    "5 0.6634404495232458\n",
    "6 0.6355640755172113\n",
    "7 0.6488212568854519\n",
    "8 0.6259146558693992\n",
    "9 0.6397803876068514\n",
    "10 0.6189791332207973\n",
    "11 0.6285574131056153\n",
    "12 0.6162813529025942\n",
    "13 0.6258473169720228\n",
    "14 0.6120803909664643\n",
    "\n",
    "17m 20s\n",
    "\n",
    "\n",
    "Submission 4\n",
    "added plural to dale, very slight increase\n",
    "1 0.668257413183145\n",
    "2 0.6126109670655668\n",
    "3 0.6774073128977224\n",
    "4 0.6339482434381662\n",
    "5 0.6680421902150359\n",
    "6 0.6356128388286275\n",
    "7 0.6540611829398212\n",
    "8 0.6241868282579967\n",
    "9 0.6428127641844336\n",
    "10 0.6171953886598779\n",
    "11 0.6298598263970768\n",
    "12 0.618206900202975\n",
    "13 0.6238640555630808\n",
    "14 0.6136176874161184\n",
    "\n",
    "\n",
    "add position and complex\n",
    "1 0.6775388554327088\n",
    "2 0.6166385320256123\n",
    "3 0.6824216345750901\n",
    "4 0.6372908738125417\n",
    "5 0.6681370214586604\n",
    "6 0.6330719335337368\n",
    "\n",
    "add length of definition\n",
    "1 0.7142974520544537\n",
    "2 0.6392006863590715\n",
    "3 0.7185837970831896\n",
    "4 0.6562322581550614\n",
    "5 0.6767755930256228\n",
    "6 0.638215011403038\n",
    "7 0.6478298861631056\n",
    "8 0.6014318744187663\n",
    "9 0.6113716172856284\n",
    "\n",
    "add mean complexity of each word\n",
    "1 0.6645660311458911\n",
    "3 0.6825219784240113\n",
    "5 0.6532568645394083\n",
    "7 0.6348892638844663\n",
    "\n",
    "remove positio\n",
    "1 0.6756303700338743\n",
    "3 0.6742453028316306\n",
    "5 0.6545457828350185\n",
    "7 0.6446028971371262\n",
    "\n",
    "\n",
    "\n",
    "1 0.6555592248380314\n",
    "3 0.6320723342984209\n",
    "5 0.6318018365113016\n",
    "7 0.630873612925929\n",
    "5m 8.4s\n",
    "\n",
    "\n",
    "1 0.6978174350266003\n",
    "3 0.7097100801794356\n",
    "5 0.7012763281982017\n",
    "7 0.6846625180178428\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 3, 0.25):\n",
    "    scores = []\n",
    "    for _ in range(1):\n",
    "        X_train, y_train, X_test, y_test = generate_data(20)\n",
    "        clf = SVC(kernel = 'rbf', C = i, gamma = 'auto', class_weight = 'balanced')\n",
    "        preds = clf.fit(X_train, y_train).predict(X_test)\n",
    "        scor = balanced_accuracy_score(y_test, preds)\n",
    "        scores.append(scor)\n",
    "    print(i, scor.mean())\n",
    "\"\"\"\n",
    "C\n",
    "2.0 0.7989526768510238\n",
    "2.05 0.7663162573389564\n",
    "2.0999999999999996 0.8071139172438091\n",
    "2.1499999999999995 0.7817640548070683\n",
    "2.1999999999999993 0.7849235827168971\n",
    "2.249999999999999 0.8002323036630431\n",
    "2.299999999999999 0.8006677849020192\n",
    "2.3499999999999988 0.8026971693074595\n",
    "2.3999999999999986 0.7829305179191633\n",
    "2.4499999999999984 0.8000819070214088\n",
    "2.4999999999999982 0.8144846512576605\n",
    "2.549999999999998 0.7584803934346462\n",
    "2.599999999999998 0.8094465648854962\n",
    "2.6499999999999977 0.8028424302827774\n",
    "2.6999999999999975 0.8026711563768261\n",
    "2.7499999999999973 0.7883496555315228\n",
    "2.799999999999997 0.8169983162406245\n",
    "2.849999999999997 0.8040404040404041\n",
    "2.899999999999997 0.7843753853742755\n",
    "2.9499999999999966 0.7891142191142191\n",
    "2.9999999999999964 0.7970483341584613\n",
    "3.0499999999999963 0.7826048329779673\n",
    "3.099999999999996 0.7996438000040306\n",
    "3.149999999999996 0.8004216348551481\n",
    "3.1999999999999957 0.7975259473811248\n",
    "3.2499999999999956 0.8104505935831237\n",
    "3.2999999999999954 0.7923782416192284\n",
    "3.349999999999995 0.8022344996930633\n",
    "3.399999999999995 0.8079854522454143\n",
    "3.449999999999995 0.8289995549181544\n",
    "3.4999999999999947 0.7932573090463799\n",
    "3.5499999999999945 0.8008438228438228\n",
    "3.5999999999999943 0.809004662004662\n",
    "3.649999999999994 0.8074961878029119\n",
    "3.699999999999994 0.816032837149498\n",
    "3.749999999999994 0.7907520259618133\n",
    "3.7999999999999936 0.8251874293930368\n",
    "3.8499999999999934 0.7792741165234002\n",
    "3.8999999999999932 0.796911421911422\n",
    "3.949999999999993 0.8119436242798217\n",
    "\n",
    "gamma\n",
    "2.0 0.7989526768510238\n",
    "2.05 0.7663162573389564\n",
    "2.0999999999999996 0.8071139172438091\n",
    "2.1499999999999995 0.7817640548070683\n",
    "2.1999999999999993 0.7849235827168971\n",
    "2.249999999999999 0.8002323036630431\n",
    "2.299999999999999 0.8006677849020192\n",
    "2.3499999999999988 0.8026971693074595\n",
    "2.3999999999999986 0.7829305179191633\n",
    "2.4499999999999984 0.8000819070214088\n",
    "2.4999999999999982 0.8144846512576605\n",
    "2.549999999999998 0.7584803934346462\n",
    "2.599999999999998 0.8094465648854962\n",
    "2.6499999999999977 0.8028424302827774\n",
    "2.6999999999999975 0.8026711563768261\n",
    "2.7499999999999973 0.7883496555315228\n",
    "2.799999999999997 0.8169983162406245\n",
    "2.849999999999997 0.8040404040404041\n",
    "2.899999999999997 0.7843753853742755\n",
    "2.9499999999999966 0.7891142191142191\n",
    "2.9999999999999964 0.7970483341584613\n",
    "3.0499999999999963 0.7826048329779673\n",
    "3.099999999999996 0.7996438000040306\n",
    "3.149999999999996 0.8004216348551481\n",
    "3.1999999999999957 0.7975259473811248\n",
    "3.2499999999999956 0.8104505935831237\n",
    "3.2999999999999954 0.7923782416192284\n",
    "3.349999999999995 0.8022344996930633\n",
    "3.399999999999995 0.8079854522454143\n",
    "3.449999999999995 0.8289995549181544\n",
    "3.4999999999999947 0.7932573090463799\n",
    "3.5499999999999945 0.8008438228438228\n",
    "3.5999999999999943 0.809004662004662\n",
    "3.649999999999994 0.8074961878029119\n",
    "3.699999999999994 0.816032837149498\n",
    "3.749999999999994 0.7907520259618133\n",
    "3.7999999999999936 0.8251874293930368\n",
    "3.8499999999999934 0.7792741165234002\n",
    "3.8999999999999932 0.796911421911422\n",
    "3.949999999999993 0.8119436242798217\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-733e40f4013f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_data' is not defined"
     ]
    }
   ],
   "source": [
    "for x in range(3, 10, 1):\n",
    "    X_train, y_train, X_test, y_test = generate_data(15)\n",
    "    clf = SVC(kernel = 'rbf', C = x, gamma = 'auto', class_weight = 'balanced')\n",
    "    preds = clf.fit(X_train, y_train).predict(X_test)\n",
    "    print(x, balanced_accuracy_score(y_test, preds))\n",
    "    print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.6417075445685437\n",
      "4 0.6454946367965795\n",
      "5 0.6517582320321622\n",
      "6 0.6578941724735413\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-94227f8ccdb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'complex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#print(preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(3, 10, 1):\n",
    "    X_train = featurize_df(train)\n",
    "    y_train = train['complex'].values\n",
    "    clf = SVC(kernel = 'rbf', C = x, gamma = 'auto', class_weight = 'balanced')\n",
    "    preds = cross_validate(clf, X_train, y_train, cv=10)\n",
    "    print(x, sum(preds[\"test_score\"])/len(preds[\"test_score\"]))\n",
    "    #print(preds)\n",
    "\"\"\"\n",
    "0.6378813657407407\n",
    "[[6127  785]\n",
    " [ 458  292]]\n",
    " alll\n",
    "\n",
    " 6 0.7551295100438792\n",
    " 1 0.7431117473047818\n",
    "2 0.7449445297367588\n",
    "3 0.7422060790915064\n",
    "\n",
    "\n",
    "1 0.7380241080334012\n",
    "2 0.7420758712014189\n",
    "3 0.7500399985021838\n",
    "4 0.7508234585258083\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = generate_data(15)\n",
    "clf = SVC(kernel = 'rbf', C = 3, gamma = 'auto', class_weight = 'balanced')\n",
    "preds = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(3, balanced_accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-6c97b1d53dd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussiannb_predicitons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mscor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_data' is not defined"
     ]
    }
   ],
   "source": [
    "def gaussiannb_predicitons(X_train, y_train, X_test):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train, )\n",
    "    return model.predict(X_test)\n",
    "\n",
    "X_train, y_train, X_test, y_test = generate_data()\n",
    "preds = gaussiannb_predicitons(X_train, y_train, X_test)\n",
    "scor = balanced_accuracy_score(y_test, preds)\n",
    "print(scor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "def gaussianprocess_classifier(X_train, y_train, X_test):\n",
    "    model = GaussianProcessClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "X_train, y_train, X_test, y_test = generate_data()\n",
    "preds = gaussianprocess_classifier(X_train, y_train, X_test)\n",
    "print(balanced_accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def svm_classifier(X_train, y_train, X_test):\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "X_train, y_train, X_test, y_test = generate_data()\n",
    "preds = svm_classifier(X_train, y_train, X_test)\n",
    "print(balanced_accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def lineardiscriminant_classifier(X_train, y_train, X_test):\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "\n",
    "scor = []\n",
    "for _ in range(1):\n",
    "    X_train, y_train, X_test, y_test = generate_data()\n",
    "    preds = gaussianprocess_classifier(X_train, y_train, X_test)\n",
    "    scor.append(balanced_accuracy_score(y_test, preds))\n",
    "print(cupy.array(scor).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn_predicitons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a3a7789a20fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'complex'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_predicitons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'knn_predicitons' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = featurize_df(train)\n",
    "y_train = train['complex'].values\n",
    "X_test = featurize_df(test)\n",
    "df = pd.DataFrame()\n",
    "df['id'] = test.index + len(train) + 1\n",
    "df['complex'] = knn_predicitons(X_train, y_train, X_test, neighbours=5)\n",
    "df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = featurize_df(train)\n",
    "y_train = train['complex'].values\n",
    "X_test = featurize_df(test)\n",
    "df = pd.DataFrame()\n",
    "df['id'] = test.index + len(train) + 1\n",
    "clf = SVC(kernel = 'rbf', C = 3, gamma = 'auto', class_weight = 'balanced')\n",
    "df['complex'] = clf.fit(X_train, y_train).predict(X_test)\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    }
   ],
   "source": [
    "print(submission['complex'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [ abs(nr_consoane(x)-nr_vowels(x)) for x in train[train[\"complex\"] == False]['token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(arr)/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(arr)/len(arr))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b455c340f5909324bcb78ef01d475f4eedf82c96c915f98f0f532100f1af7503"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
